{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing","metadata":{"_uuid":"ced5a170-72f0-4212-9917-81761ac23d94","_cell_guid":"933eca5f-629d-4fdc-b80a-f2234befafe5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-27T12:09:34.386462Z","iopub.execute_input":"2023-01-27T12:09:34.386987Z","iopub.status.idle":"2023-01-27T12:09:35.044720Z","shell.execute_reply.started":"2023-01-27T12:09:34.386845Z","shell.execute_reply":"2023-01-27T12:09:35.043142Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/jan_train.csv')\ntest = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/jan_test.csv')\nkey = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/answer_key.csv')","metadata":{"_uuid":"4308af9f-b7af-4795-983b-03cee8bcd281","_cell_guid":"7a879c4b-d83c-4861-adeb-eec03fd6f033","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-27T12:09:35.047419Z","iopub.execute_input":"2023-01-27T12:09:35.048436Z","iopub.status.idle":"2023-01-27T12:09:39.308165Z","shell.execute_reply.started":"2023-01-27T12:09:35.048386Z","shell.execute_reply":"2023-01-27T12:09:39.306727Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"_uuid":"df989526-dce1-401c-8fe1-b4eb8ed8439e","_cell_guid":"bebf2846-3d4a-4b0e-b131-441f12e11ca2","execution":{"iopub.status.busy":"2023-01-27T12:09:39.310298Z","iopub.execute_input":"2023-01-27T12:09:39.310965Z","iopub.status.idle":"2023-01-27T12:09:39.373928Z","shell.execute_reply.started":"2023-01-27T12:09:39.310934Z","shell.execute_reply":"2023-01-27T12:09:39.372374Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 503227 entries, 0 to 503226\nData columns (total 15 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   id      503227 non-null  int64  \n 1   epoch   503227 non-null  object \n 2   sat_id  503227 non-null  int64  \n 3   x       503227 non-null  float64\n 4   y       503227 non-null  float64\n 5   z       503227 non-null  float64\n 6   Vx      503227 non-null  float64\n 7   Vy      503227 non-null  float64\n 8   Vz      503227 non-null  float64\n 9   x_sim   503227 non-null  float64\n 10  y_sim   503227 non-null  float64\n 11  z_sim   503227 non-null  float64\n 12  Vx_sim  503227 non-null  float64\n 13  Vy_sim  503227 non-null  float64\n 14  Vz_sim  503227 non-null  float64\ndtypes: float64(12), int64(2), object(1)\nmemory usage: 57.6+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"train['epoch'] = pd.to_datetime(train['epoch'])","metadata":{"_uuid":"c768f543-ea17-4b0b-9050-908439beff60","_cell_guid":"f8a55399-c34d-43c0-963f-b2311c54782f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-27T12:09:39.377101Z","iopub.execute_input":"2023-01-27T12:09:39.377620Z","iopub.status.idle":"2023-01-27T12:09:39.475374Z","shell.execute_reply.started":"2023-01-27T12:09:39.377568Z","shell.execute_reply":"2023-01-27T12:09:39.473666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X = train[['id', 'sat_id', 'x_sim','y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim']].copy()\nY = train[['x', 'y', 'z', 'Vx', 'Vy', 'Vz']]\nfrom sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler()\nX_scale = min_max_scaler.fit_transform(X)","metadata":{"_uuid":"6ab601d5-b716-4e17-8809-7b36a516ff61","_cell_guid":"a294c56d-4dbf-405f-ad62-fefc140f5eef","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-27T12:09:39.477404Z","iopub.execute_input":"2023-01-27T12:09:39.477861Z","iopub.status.idle":"2023-01-27T12:09:39.563148Z","shell.execute_reply.started":"2023-01-27T12:09:39.477790Z","shell.execute_reply":"2023-01-27T12:09:39.561362Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing as pp\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport random\nimport pickle\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import *\nfrom sklearn import *","metadata":{"execution":{"iopub.status.busy":"2023-01-27T12:09:39.565504Z","iopub.execute_input":"2023-01-27T12:09:39.565989Z","iopub.status.idle":"2023-01-27T12:09:40.107276Z","shell.execute_reply.started":"2023-01-27T12:09:39.565943Z","shell.execute_reply":"2023-01-27T12:09:40.105845Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.1)\nX_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n\nprint(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)","metadata":{"_uuid":"ba9dce35-698b-46cd-b6f7-9f4161ba13ce","_cell_guid":"cc168471-edc1-4586-afbc-2fd509bae3df","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-01-27T12:09:40.108875Z","iopub.execute_input":"2023-01-27T12:09:40.109502Z","iopub.status.idle":"2023-01-27T12:09:40.266341Z","shell.execute_reply.started":"2023-01-27T12:09:40.109466Z","shell.execute_reply":"2023-01-27T12:09:40.265404Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(452904, 8) (25161, 8) (25162, 8) (452904, 6) (25161, 6) (25162, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/jan_test.csv')\ntest = test[['id', 'sat_id', 'x_sim','y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim']].copy()\ntest_scale = min_max_scaler.transform(test)","metadata":{"execution":{"iopub.status.busy":"2023-01-27T12:09:40.267842Z","iopub.execute_input":"2023-01-27T12:09:40.268171Z","iopub.status.idle":"2023-01-27T12:09:40.546857Z","shell.execute_reply.started":"2023-01-27T12:09:40.268137Z","shell.execute_reply":"2023-01-27T12:09:40.545264Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# MULTI-LAYER PERCEPTRON MODEL","metadata":{}},{"cell_type":"code","source":"# LINEAR CLASSIFICATION AT OUTPUT LAYER - EPOCHS = 5 \nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# define the model\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=8, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(6, activation='linear'))\n\n# compile the model\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy'])\n\n# fit the model to the training data\nmodel.fit(X_train, Y_train, epochs=5, batch_size=32, validation_data=(X_val, Y_val))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-27T12:14:56.033339Z","iopub.execute_input":"2023-01-27T12:14:56.033792Z","iopub.status.idle":"2023-01-27T12:18:30.334392Z","shell.execute_reply.started":"2023-01-27T12:14:56.033751Z","shell.execute_reply":"2023-01-27T12:18:30.332756Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/5\n14154/14154 [==============================] - 44s 3ms/step - loss: 243347104.0000 - accuracy: 0.4417 - val_loss: 198437344.0000 - val_accuracy: 0.5199\nEpoch 2/5\n14154/14154 [==============================] - 43s 3ms/step - loss: 186180896.0000 - accuracy: 0.5673 - val_loss: 163571456.0000 - val_accuracy: 0.6328\nEpoch 3/5\n14154/14154 [==============================] - 43s 3ms/step - loss: 123156168.0000 - accuracy: 0.7139 - val_loss: 93304200.0000 - val_accuracy: 0.7571\nEpoch 4/5\n14154/14154 [==============================] - 43s 3ms/step - loss: 91372224.0000 - accuracy: 0.7471 - val_loss: 87281536.0000 - val_accuracy: 0.7420\nEpoch 5/5\n14154/14154 [==============================] - 42s 3ms/step - loss: 87668608.0000 - accuracy: 0.7344 - val_loss: 84173192.0000 - val_accuracy: 0.7345\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f78c065a950>"},"metadata":{}}]},{"cell_type":"code","source":"# SIGMOID CLASSIFICATION - 1 EPOCH \n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# define the model\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=8, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(6, activation='sigmoid'))\n\n# compile the model\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics = ['accuracy'])\n\n# fit the model to the training data\nmodel.fit(X_train, Y_train, epochs=1, batch_size=32, validation_data=(X_val, Y_val))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-27T12:22:52.903045Z","iopub.execute_input":"2023-01-27T12:22:52.903604Z","iopub.status.idle":"2023-01-27T12:23:33.228944Z","shell.execute_reply.started":"2023-01-27T12:22:52.903563Z","shell.execute_reply":"2023-01-27T12:23:33.227645Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"14154/14154 [==============================] - 40s 3ms/step - loss: 287436672.0000 - accuracy: 0.7671 - val_loss: 285982048.0000 - val_accuracy: 0.8138\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f78c01e9b50>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('MLPmodel.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-27T12:24:30.036382Z","iopub.execute_input":"2023-01-27T12:24:30.036855Z","iopub.status.idle":"2023-01-27T12:24:30.066412Z","shell.execute_reply.started":"2023-01-27T12:24:30.036794Z","shell.execute_reply":"2023-01-27T12:24:30.064875Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# EXTENDED GRADIENT BOOST MODEL ","metadata":{"execution":{"iopub.status.busy":"2023-01-16T16:49:15.884102Z","iopub.execute_input":"2023-01-16T16:49:15.884511Z","iopub.status.idle":"2023-01-16T16:49:17.953199Z","shell.execute_reply.started":"2023-01-16T16:49:15.884480Z","shell.execute_reply":"2023-01-16T16:49:17.951293Z"}}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n\n# Convert the data into DMatrix format, which is the format expected by XGBoost\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)\n\n# Set the parameters for the XGBoost model\nparam = {\n    'max_depth': 5, \n    'eta': 0.1, \n    'objective': 'reg:squarederror'\n}\n\n# Train the model using XGBoost\nmodel = xgb.train(param, dtrain, num_boost_round=100)\n\n# Make predictions on the test data\ny_pred = model.predict(dtest)\n\n# Evaluate the model using mean squared error\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean squared error:\", mse)\n\n# Use the trained model to make a prediction on SAMPLE DATA\nnew_data = pd.DataFrame({'id': [1001], 'sat_id': [56], 'x_sim': [-1356.78], 'y_sim': [2356.78], \n                        'z_sim': [3456.78], 'Vx_sim': [56.78], 'Vy_sim': [-89.78], 'Vz_sim': [90.78]})\ndnew = xgb.DMatrix(new_data) \nprediction = model.predict(dnew)\n\n# The prediction will be an array with 6 values, representing the position and speed of the satellite\n# [x, y, z, Vx, Vy, Vz]\nprint(\"Predicted position and speed of satellite:\", prediction)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T20:53:21.626640Z","iopub.execute_input":"2023-01-15T20:53:21.627074Z","iopub.status.idle":"2023-01-15T20:57:07.016512Z","shell.execute_reply.started":"2023-01-15T20:53:21.627041Z","shell.execute_reply":"2023-01-15T20:57:07.015132Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Mean squared error: 10906422.928717488\nPredicted position and speed of satellite: [[-3.6037068e+03 -2.8779192e+03  1.0924578e+04  6.1423826e-01\n  -1.7504978e+00  6.0496998e+00]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib\ntest = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/jan_test.csv')\ntest = test[['id', 'sat_id', 'x_sim','y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim']].copy()\n# test_scale = min_max_scaler.transform(test)\ntest_data = pd.DataFrame(test, columns=['id', 'sat_id', 'x_sim','y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim'])\ndnew = xgb.DMatrix(test_data) \nmodel = joblib.load(\"/kaggle/input/sgb-model/xgb.joblib\")\npredictions = model.predict( dnew ) \npredictions_df = pd.DataFrame( predictions , columns = ['x', 'y', 'z', 'Vx', 'Vy', 'Vz'])\npredictions_df.to_csv('predictions.csv',index = False ) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib \nimport xgboost as xgb \nimport pandas as pd \n\nmodel = joblib.load(\"/kaggle/input/sgb-model/xgb.joblib\")\n# convert test data into DMatrix object\ntest = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/jan_test.csv')\ntest = test[['id', 'sat_id', 'x_sim','y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim']].copy()\ntest_data = pd.DataFrame(test, columns=['id', 'sat_id', 'x_sim','y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim'])\ndtest = xgb.DMatrix(test_data) \n\n# make predictions using the model\npredictions = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n\n# load the key file\nkey = pd.read_csv('/kaggle/input/predict-the-positions-and-speeds-of-600-satellites/answer_key.csv')\n\n# calculate the score\nscore = metrics.r2_score(key, predictions)\nprint('XGBoost score:', score)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-18T17:07:37.793351Z","iopub.execute_input":"2023-01-18T17:07:37.794647Z","iopub.status.idle":"2023-01-18T17:07:39.170358Z","shell.execute_reply.started":"2023-01-18T17:07:37.794603Z","shell.execute_reply":"2023-01-18T17:07:39.169372Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/core.py:94: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n  UserWarning\n","output_type":"stream"},{"name":"stdout","text":"XGBoost score: 0.7571616636425053\n","output_type":"stream"}]},{"cell_type":"code","source":"# PKL TO JSON CONVERSION FOR MERN STACK APPLICATION \nimport xgboost as xgb\nimport joblib\nimport json\n\n# Load the model\nmodel = joblib.load(\"/kaggle/input/sgb-model/xgb.joblib\")\n\n# Convert the model to a dictionary\nmodel_dict = model.__dict__\n\n# Serialize the dictionary to a JSON string\nmodel_json = json.dumps(model_dict)\n\n# Save the JSON string to a file\nwith open(\"xgb.json\", \"w\") as f:\n    f.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2023-01-17T12:26:30.481416Z","iopub.execute_input":"2023-01-17T12:26:30.482083Z","iopub.status.idle":"2023-01-17T12:26:31.835451Z","shell.execute_reply.started":"2023-01-17T12:26:30.481996Z","shell.execute_reply":"2023-01-17T12:26:31.833844Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2469869489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Serialize the dictionary to a JSON string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Save the JSON string to a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n","\u001b[0;32m/opt/conda/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Object of type c_void_p is not JSON serializable"],"ename":"TypeError","evalue":"Object of type c_void_p is not JSON serializable","output_type":"error"}]},{"cell_type":"markdown","source":"# RANDOM FOREST REGRESSOR ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# create regressor object\nregressor = RandomForestRegressor(n_estimators = 100)\n\n# fit the regressor with x and y data\nregressor.fit(X_train, Y_train)\n\nregressor.score(X_test, Y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'rf_regressor.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-01-15T20:52:18.712200Z","iopub.execute_input":"2023-01-15T20:52:18.712632Z","iopub.status.idle":"2023-01-15T20:52:18.721630Z","shell.execute_reply.started":"2023-01-15T20:52:18.712596Z","shell.execute_reply":"2023-01-15T20:52:18.720371Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/rf_regressor.joblib","text/html":"<a href='rf_regressor.joblib' target='_blank'>rf_regressor.joblib</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"# Import the necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Load the trained model\nfilename = '/kaggle/working/regressor.pkl'\nloaded_model = pickle.load(open(filename, 'rb'))\n\n# Create a new synthetic input data point\nnew_data = pd.DataFrame({'id': [1001], 'sat_id': [56], 'x_sim': [-1356.78], 'y_sim': [2356.78], \n                        'z_sim': [3456.78], 'Vx_sim': [56.78], 'Vy_sim': [-89.78], 'Vz_sim': [90.78]})\n\n# Scale the new input data\nmin_max_scaler = preprocessing.MinMaxScaler()\nnew_data_scale = min_max_scaler.fit_transform(new_data)\n\n# Use the trained model to make a prediction\nprediction = loaded_model.predict(new_data_scale)\n\n# The prediction will be an array with 6 values, representing the position and speed of the satellite\n# [x, y, z, Vx, Vy, Vz]\nprint(\"Predicted position and speed of satellite:\", prediction)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-15T20:37:38.845820Z","iopub.status.idle":"2023-01-15T20:37:38.846416Z","shell.execute_reply.started":"2023-01-15T20:37:38.846120Z","shell.execute_reply":"2023-01-15T20:37:38.846146Z"},"trusted":true},"execution_count":null,"outputs":[]}]}